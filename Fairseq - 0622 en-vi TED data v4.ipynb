{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHBsw0sUrGaQ"
   },
   "source": [
    "# **HOW TO TRAIN NEW MODEL (En to Vi)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQpoxG9RKlI-"
   },
   "source": [
    "Phiên bản V1 nhằm chạy thử model TED anh - việt với các đặc điểm:\n",
    "\n",
    "1 - Chạy  7 epoch\n",
    "\n",
    "2 - Thực hiện trên máy local\n",
    "\n",
    "3 - Chạy với tập train theo dạng (s1|||tar_best))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPLcxMFbs29E"
   },
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cTqTtTOzjYqG",
    "outputId": "e8584fba-a997-4399-feef-90713380fb45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning Moses github repository (for tokenization scripts)...\n",
      "Cloning into 'mosesdecoder'...\n",
      "remote: Enumerating objects: 20, done.\u001b[K\n",
      "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
      "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
      "remote: Total 147592 (delta 5), reused 11 (delta 3), pack-reused 147572\u001b[K\n",
      "Receiving objects: 100% (147592/147592), 129.76 MiB | 7.84 MiB/s, done.\n",
      "Resolving deltas: 100% (114030/114030), done.\n",
      "Checking out files: 100% (3470/3470), done.\n",
      "Cloning Subword NMT repository (for BPE pre-processing)...\n",
      "Cloning into 'subword-nmt'...\n",
      "remote: Enumerating objects: 576, done.\u001b[K\n",
      "remote: Total 576 (delta 0), reused 0 (delta 0), pack-reused 576\u001b[K\n",
      "Receiving objects: 100% (576/576), 233.12 KiB | 3.33 MiB/s, done.\n",
      "Resolving deltas: 100% (349/349), done.\n",
      "Downloading data from https://github.com/hoangtrungchinh/clc_data/raw/master/en_vi_iwslt.tar.gz...\n",
      "--2020-11-21 06:37:56--  https://github.com/hoangtrungchinh/clc_data/raw/master/en_vi_iwslt.tar.gz\n",
      "Resolving github.com (github.com)... 192.30.255.113\n",
      "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/hoangtrungchinh/clc_data/master/en_vi_iwslt.tar.gz [following]\n",
      "--2020-11-21 06:37:56--  https://raw.githubusercontent.com/hoangtrungchinh/clc_data/master/en_vi_iwslt.tar.gz\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9044100 (8.6M) [application/octet-stream]\n",
      "Saving to: ‘en_vi_iwslt.tar.gz’\n",
      "\n",
      "en_vi_iwslt.tar.gz  100%[===================>]   8.62M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2020-11-21 06:37:57 (62.8 MB/s) - ‘en_vi_iwslt.tar.gz’ saved [9044100/9044100]\n",
      "\n",
      "Data successfully downloaded.\n",
      "IWSLT15.TED.tst2013.en-vi.en\n",
      "IWSLT15.TED.tst2013.en-vi.vi\n",
      "IWSLT15.TED.tst2012.en-vi.en\n",
      "IWSLT15.TED.tst2012.en-vi.vi\n",
      "train.en\n",
      "train.vi\n",
      "IWSLT15.TED.tst2015.en-vi.en\n",
      "IWSLT15.TED.tst2015.en-vi.vi\n",
      "pre-processing train data...\n",
      "Tokenizer Version 1.1\n",
      "Language: en\n",
      "Number of threads: 8\n",
      "\n",
      "Tokenizer Version 1.1\n",
      "Language: vi\n",
      "Number of threads: 8\n",
      "WARNING: No known abbreviations for language 'vi', attempting fall-back to English version...\n",
      "\n",
      "clean-corpus.perl: processing iwslt-iwslt-tokenized.en-vi/tmp/train.tags.en-vi.tok.en & .vi to iwslt-iwslt-tokenized.en-vi/tmp/train.tags.en-vi.clean, cutoff 1-175, ratio 1.5\n",
      "..........(100000).\n",
      "Input sentences: 117055  Output sentences:  114291\n",
      "pre-processing valid/test data...\n",
      "Tokenizer Version 1.1\n",
      "Language: en\n",
      "Number of threads: 8\n",
      "\n",
      "Tokenizer Version 1.1\n",
      "Language: vi\n",
      "Number of threads: 8\n",
      "WARNING: No known abbreviations for language 'vi', attempting fall-back to English version...\n",
      "\n",
      "creating train, valid, test...\n",
      "learn_bpe.py on iwslt-iwslt-tokenized.en-vi/tmp/train.en-vi...\n",
      "apply_bpe.py to train.en...\n",
      "apply_bpe.py to valid.en...\n",
      "apply_bpe.py to test.en...\n",
      "apply_bpe.py to train.vi...\n",
      "apply_bpe.py to valid.vi...\n",
      "apply_bpe.py to test.vi...\n",
      "/usr/local/lib/python3.6/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "2020-11-21 06:39:21 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='iwslt-data-bin/tokenized.en-vi', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, reset_logging=True, scoring='bleu', seed=1, source_lang='en', srcdict=None, target_lang='vi', task='translation', tensorboard_logdir=None, testpref='iwslt-tokenized.en-vi/test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='iwslt-tokenized.en-vi/train', user_dir=None, validpref='iwslt-tokenized.en-vi/valid', wandb_project=None, workers=20)\n",
      "2020-11-21 06:39:43 | INFO | fairseq_cli.preprocess | [en] Dictionary: 7768 types\n",
      "2020-11-21 06:40:06 | INFO | fairseq_cli.preprocess | [en] iwslt-tokenized.en-vi/train.en: 109322 sents, 2874159 tokens, 0.0% replaced by <unk>\n",
      "2020-11-21 06:40:06 | INFO | fairseq_cli.preprocess | [en] Dictionary: 7768 types\n",
      "2020-11-21 06:40:08 | INFO | fairseq_cli.preprocess | [en] iwslt-tokenized.en-vi/valid.en: 4969 sents, 128336 tokens, 0.00156% replaced by <unk>\n",
      "2020-11-21 06:40:08 | INFO | fairseq_cli.preprocess | [en] Dictionary: 7768 types\n",
      "2020-11-21 06:40:09 | INFO | fairseq_cli.preprocess | [en] iwslt-tokenized.en-vi/test.en: 1080 sents, 26128 tokens, 0.0191% replaced by <unk>\n",
      "2020-11-21 06:40:09 | INFO | fairseq_cli.preprocess | [vi] Dictionary: 6720 types\n",
      "2020-11-21 06:40:37 | INFO | fairseq_cli.preprocess | [vi] iwslt-tokenized.en-vi/train.vi: 109322 sents, 2956068 tokens, 0.0% replaced by <unk>\n",
      "2020-11-21 06:40:37 | INFO | fairseq_cli.preprocess | [vi] Dictionary: 6720 types\n",
      "2020-11-21 06:40:40 | INFO | fairseq_cli.preprocess | [vi] iwslt-tokenized.en-vi/valid.vi: 4969 sents, 131647 tokens, 0.0319% replaced by <unk>\n",
      "2020-11-21 06:40:40 | INFO | fairseq_cli.preprocess | [vi] Dictionary: 6720 types\n",
      "2020-11-21 06:40:41 | INFO | fairseq_cli.preprocess | [vi] iwslt-tokenized.en-vi/test.vi: 1080 sents, 28544 tokens, 0.855% replaced by <unk>\n",
      "2020-11-21 06:40:41 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to iwslt-data-bin/tokenized.en-vi\n",
      "/usr/local/lib/python3.6/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "2020-11-21 06:40:45 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'tensorboard_logdir': None, 'wandb_project': None, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': True}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'broadcast_buffers': False, 'distributed_wrapper': 'DDP', 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'tpu': False, 'distributed_num_procs': 0}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4096, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4096, 'batch_size_valid': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'iwslt-checkpoints/fconv_wmt_en_vi', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'model_parallel_size': 1, 'distributed_rank': 0}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': False, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer', attention_dropout=0.0, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='iwslt-data-bin/tokenized.en-vi', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}', eval_bleu_detok='moses', eval_bleu_detok_args=None, eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=0, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='iwslt-checkpoints/fconv_wmt_en_vi', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=400, weight_decay=0.0001, zero_sharding='none'), 'task': Namespace(_name='translation', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer', attention_dropout=0.0, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='iwslt-data-bin/tokenized.en-vi', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}', eval_bleu_detok='moses', eval_bleu_detok_args=None, eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=0, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='iwslt-checkpoints/fconv_wmt_en_vi', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=400, weight_decay=0.0001, zero_sharding='none'), 'criterion': Namespace(_name='label_smoothed_cross_entropy', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer', attention_dropout=0.0, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='iwslt-data-bin/tokenized.en-vi', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}', eval_bleu_detok='moses', eval_bleu_detok_args=None, eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=0, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='iwslt-checkpoints/fconv_wmt_en_vi', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=400, weight_decay=0.0001, zero_sharding='none'), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 400, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None}\n",
      "2020-11-21 06:40:45 | INFO | fairseq.tasks.translation | [en] dictionary: 7768 types\n",
      "2020-11-21 06:40:45 | INFO | fairseq.tasks.translation | [vi] dictionary: 6720 types\n",
      "2020-11-21 06:40:45 | INFO | fairseq.data.data_utils | loaded 4969 examples from: iwslt-data-bin/tokenized.en-vi/valid.en-vi.en\n",
      "2020-11-21 06:40:45 | INFO | fairseq.data.data_utils | loaded 4969 examples from: iwslt-data-bin/tokenized.en-vi/valid.en-vi.vi\n",
      "2020-11-21 06:40:45 | INFO | fairseq.tasks.translation | iwslt-data-bin/tokenized.en-vi valid en-vi 4969 examples\n",
      "2020-11-21 06:40:46 | INFO | fairseq_cli.train | TransformerModel(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (dropout_module): FairseqDropout()\n",
      "    (embed_tokens): Embedding(7768, 512, padding_idx=1)\n",
      "    (embed_positions): SinusoidalPositionalEmbedding()\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (3): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (4): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (5): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (dropout_module): FairseqDropout()\n",
      "    (embed_tokens): Embedding(6720, 512, padding_idx=1)\n",
      "    (embed_positions): SinusoidalPositionalEmbedding()\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (3): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (4): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (5): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (output_projection): Linear(in_features=512, out_features=6720, bias=False)\n",
      "  )\n",
      ")\n",
      "2020-11-21 06:40:46 | INFO | fairseq_cli.train | task: TranslationTask\n",
      "2020-11-21 06:40:46 | INFO | fairseq_cli.train | model: TransformerModel\n",
      "2020-11-21 06:40:46 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion)\n",
      "2020-11-21 06:40:46 | INFO | fairseq_cli.train | num. model params: 51556352 (num. trained: 51556352)\n",
      "2020-11-21 06:40:46 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
      "2020-11-21 06:40:46 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
      "2020-11-21 06:40:46 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and batch size per GPU = None\n",
      "2020-11-21 06:40:46 | INFO | fairseq.trainer | no existing checkpoint found iwslt-checkpoints/fconv_wmt_en_vi/checkpoint_last.pt\n",
      "2020-11-21 06:40:46 | INFO | fairseq.trainer | loading train data for epoch 1\n",
      "2020-11-21 06:40:46 | INFO | fairseq.data.data_utils | loaded 109322 examples from: iwslt-data-bin/tokenized.en-vi/train.en-vi.en\n",
      "2020-11-21 06:40:46 | INFO | fairseq.data.data_utils | loaded 109322 examples from: iwslt-data-bin/tokenized.en-vi/train.en-vi.vi\n",
      "2020-11-21 06:40:46 | INFO | fairseq.tasks.translation | iwslt-data-bin/tokenized.en-vi train en-vi 109322 examples\n",
      "epoch 001:   0% 0/828 [00:00<?, ?it/s]2020-11-21 06:40:46 | INFO | fairseq.trainer | begin training epoch 1\n",
      "epoch 001:   0% 1/828 [00:19<4:31:10, 19.67s/it]"
     ]
    }
   ],
   "source": [
    "# # Download and prepare the data\n",
    "!bash clc_fairseq/examples/translation/prepare-en-vi-iwslt.sh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RXKBIen3-URS"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0r2hhjvH-Q5o",
    "outputId": "3c345137-ae3d-41cd-e91b-17d0fe3b85a1",
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tion | example reference: nhưng cũng có một hạn chế.\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:   2%|▏      | 1/46 [00:25<19:11, 25.59s/it]\u001b[A2020-12-08 13:07:17 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:07:17 | INFO | fairseq.tasks.translation | example reference: bé ấy được sáu tháng tuổi.\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:   4%|▎      | 2/46 [00:44<17:14, 23.51s/it]\u001b[A2020-12-08 13:07:35 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:07:35 | INFO | fairseq.tasks.translation | example reference: mỗi ly chứa một loại dầu thơm khác nhau.\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:   7%|▍      | 3/46 [01:01<15:36, 21.78s/it]\u001b[A2020-12-08 13:07:50 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:07:50 | INFO | fairseq.tasks.translation | example reference: các bạn chắc hẳn đã từng nghe về khái niệm big data.\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:   9%|▌      | 4/46 [01:17<13:54, 19.87s/it]\u001b[A2020-12-08 13:08:05 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:08:05 | INFO | fairseq.tasks.translation | example reference: tôi đang nói đến việc sản xuất nhôm.\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:  11%|▊      | 5/46 [01:32<12:36, 18.44s/it]\u001b[A2020-12-08 13:08:17 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:08:17 | INFO | fairseq.tasks.translation | example reference: chúng lao vào thứ này, và chúng bay vào trong nó.\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:  13%|▉      | 6/46 [01:44<10:59, 16.48s/it]\u001b[A2020-12-08 13:08:31 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:08:31 | INFO | fairseq.tasks.translation | example reference: chúng tôi xem xét mỗi người chơi ăn hết bao nhiêu chiếc bánh\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:  15%|█      | 7/46 [01:57<10:07, 15.58s/it]\u001b[A2020-12-08 13:08:44 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:08:44 | INFO | fairseq.tasks.translation | example reference: vì vậy nó bắt đầu trở thành một sự pha trộn thú vị.\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:  17%|█▏     | 8/46 [02:11<09:26, 14.92s/it]\u001b[A2020-12-08 13:08:57 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:08:57 | INFO | fairseq.tasks.translation | example reference: chúng tôi không cần nó. chúng tôi không thích nó.\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:  20%|█▎     | 9/46 [02:24<08:50, 14.34s/it]\u001b[A2020-12-08 13:09:09 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:09:09 | INFO | fairseq.tasks.translation | example reference: bằng cách thổi phồng lên hoặc làm xẹp xuống tuỳ theo trạng thái cảm xúc của mình.\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:  22%|█▎    | 10/46 [02:36<08:14, 13.74s/it]\u001b[A2020-12-08 13:09:22 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:09:22 | INFO | fairseq.tasks.translation | example reference: & lt; speaker & gt; phil plait & lt; / speaker & gt;\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:  24%|█▍    | 11/46 [02:48<07:43, 13.25s/it]\u001b[A2020-12-08 13:09:33 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:09:33 | INFO | fairseq.tasks.translation | example reference: bà ấy nói bà không nhận ra bất cứ ai hay nơi nào trong những ảo giác đó.\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:  26%|█▌    | 12/46 [03:00<07:13, 12.76s/it]\u001b[A2020-12-08 13:09:44 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:09:44 | INFO | fairseq.tasks.translation | example reference: trong vòng ba năm, chúng tôi dự định sẽ xem xét 40% các căn bệnh.\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:  28%|█▋    | 13/46 [03:11<06:46, 12.31s/it]\u001b[A2020-12-08 13:09:56 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:09:56 | INFO | fairseq.tasks.translation | example reference: nhưng tôi tìm tấm biển cho người nói tiếng nga và những tấm biển cấm hay nhất\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:  30%|█▊    | 14/46 [03:23<06:25, 12.06s/it]\u001b[A2020-12-08 13:10:07 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:10:07 | INFO | fairseq.tasks.translation | example reference: trong quá trình làm việc, tôi luôn tìm cách khai thác và hé mở nó.\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:  33%|█▉    | 15/46 [03:34<06:05, 11.78s/it]\u001b[A2020-12-08 13:10:18 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:10:18 | INFO | fairseq.tasks.translation | example reference: vì vậy khi tôi đi đến nghiên cứu chim cánh cụt magellanic, tôi không có bất cứ vấn đề nào,\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:  35%|██    | 16/46 [03:44<05:44, 11.47s/it]\u001b[A2020-12-08 13:10:28 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:10:28 | INFO | fairseq.tasks.translation | example reference: nó sẽ làm những người già phải lên tiếng từ những góc xa của thế giới để kêu gọi sự cân bằng thế giới.\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:  37%|██▏   | 17/46 [03:55<05:24, 11.19s/it]\u001b[A2020-12-08 13:10:39 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:10:39 | INFO | fairseq.tasks.translation | example reference: và tôi nghĩ đó là phần lớn nguyên nhân của sự suy thoái về pháp lý trong các chính phủ của ta bây giờ.\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:  39%|██▎   | 18/46 [04:05<05:07, 10.99s/it]\u001b[A2020-12-08 13:10:49 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:10:49 | INFO | fairseq.tasks.translation | example reference: đó là lần đầu tôi bay ra ngoài trạm với con mắt bên trái đã bị mù và tôi không hề biết lí do tại sao.\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:  41%|██▍   | 19/46 [04:16<04:49, 10.72s/it]\u001b[A2020-12-08 13:10:59 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:10:59 | INFO | fairseq.tasks.translation | example reference: khi hợp tác để tạo nên tương lai cho trái đất này, tôi mong ta sẽ tìm được cách để giữ những đốm này sáng mãi.\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:  43%|██▌   | 20/46 [04:26<04:34, 10.57s/it]\u001b[A2020-12-08 13:11:09 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:11:09 | INFO | fairseq.tasks.translation | example reference: tiện đây nói về hệ thống lập file, chúng ta chưa bao giờ thấy các siêu liên kết này có thể vượt lên mạng nội vùng.\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:  46%|██▋   | 21/46 [04:36<04:19, 10.37s/it]\u001b[A2020-12-08 13:11:19 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:11:19 | INFO | fairseq.tasks.translation | example reference: ông ấy nghĩ, & quot; tao biết lái xe thế nào; tại sao tao cần phải có sự cấp phép của nhà nước? & quot;\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:  48%|██▊   | 22/46 [04:46<04:06, 10.26s/it]\u001b[A2020-12-08 13:11:29 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:11:29 | INFO | fairseq.tasks.translation | example reference: thực tế một con muỗi chỉ có thể di chuyển khoảng khoảng 200 yard trong toàn bộ cuộc đời của nó. chúng không di chuyển quá xa.\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:  50%|███   | 23/46 [04:55<03:52, 10.10s/it]\u001b[A2020-12-08 13:11:38 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:11:38 | INFO | fairseq.tasks.translation | example reference: tên anh là simon kuznets và bản báo cáo mà anh gửi được gọi là & quot; national UNKNOWNTOKENINREF, 1929-1932 & quot;\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:  52%|███▏  | 24/46 [05:05<03:37,  9.90s/it]\u001b[A2020-12-08 13:11:48 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:11:48 | INFO | fairseq.tasks.translation | example reference: có lẽ bạn cho rằng lực lượng mà tôi chỉ đạo toàn là những tay biệt kích mặt lạnh nắm đấm thép mang theo mình đống vũ khí kỳ quặc.\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:  54%|███▎  | 25/46 [05:15<03:27,  9.90s/it]\u001b[A2020-12-08 13:11:57 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:11:57 | INFO | fairseq.tasks.translation | example reference: hiệp chủng quốc hoa kỳ vẫn hàng ngày vi phạm những điều luật của những năm 1851 và 1868 hiệp ước fort laramie đối với người lakota.\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:  57%|███▍  | 26/46 [05:24<03:13,  9.66s/it]\u001b[A2020-12-08 13:12:07 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:12:07 | INFO | fairseq.tasks.translation | example reference: vì thế việc tất cả chúng tôi cần làm là lấy các dna này đặt nó vào một liệu pháp gen trung gian, giống như virus, và đặt nó vào các nơ-ron.\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:  59%|███▌  | 27/46 [05:34<03:05,  9.75s/it]\u001b[A2020-12-08 13:12:17 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:12:17 | INFO | fairseq.tasks.translation | example reference: con người, tất nhiên, nơi chốn, và năng lượng vô tận của tuổi trẻ. tôi đang bắt đầu mất sự tự lập và điều đó khiến tôi lo sợ.\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:  61%|███▋  | 28/46 [05:44<02:55,  9.77s/it]\u001b[A2020-12-08 13:12:26 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:12:26 | INFO | fairseq.tasks.translation | example reference: nhưng đến lớp 11, 12, còn không đến 10% học sinh còn hào hứng với môn khoa học, nói gì đến chuyện coi nó là một nghề.\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:  63%|███▊  | 29/46 [05:52<02:40,  9.45s/it]\u001b[A2020-12-08 13:12:35 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:12:35 | INFO | fairseq.tasks.translation | example reference: một vài ngườii sẽ cảm thấy sợ hãi: tôi sẽ nói với các bạn đôi điều sẽ có thể làm bạn muốn ói nhưng sẽ ổn thôi.\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:  65%|███▉  | 30/46 [06:02<02:31,  9.48s/it]\u001b[A2020-12-08 13:12:44 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:12:44 | INFO | fairseq.tasks.translation | example reference: và kể từ đó, tôi đã được làm một số việc rất thú vị -- từ gặp gỡ tổng thống cho đến việc đứng trên sân khấu này để nói với tất cả các bạn.\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:  67%|████  | 31/46 [06:11<02:19,  9.33s/it]\u001b[A2020-12-08 13:12:53 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:12:53 | INFO | fairseq.tasks.translation | example reference: và giờ tôi đánh cuộc rằng, trong tất cả các khán giả tại đây, cá bạn đang nghĩ tới những thứ công nghệ vĩ đại nào đó, những thứ mà tôi thậm chí còn chưa biết đến, tôi tuyệt đối chắc chắn.\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:  70%|████▏ | 32/46 [06:20<02:08,  9.19s/it]\u001b[A2020-12-08 13:13:02 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:13:02 | INFO | fairseq.tasks.translation | example reference: khi nó hé mở hệ gen, chia tách thành hai tế bào và giải mã lại, tại sao nó lại không trở thành một con mắt, hay một lá gan, khi mà chúng có tất cả các gen cần thiết như vậy?\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:  72%|████▎ | 33/46 [06:29<01:59,  9.21s/it]\u001b[A2020-12-08 13:13:11 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:13:11 | INFO | fairseq.tasks.translation | example reference: dù sao chăng nữa, đây là một trong những mẩu quảng cáo tôi hài lòng nhất, vì chúng có sự chỉ đạo nghệ thuật rất tỉ mỉ, trong bức hình này, có vẻ như cô bé đang thật sự nhìn vào máy tính.\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:  74%|████▍ | 34/46 [06:37<01:47,  8.99s/it]\u001b[A2020-12-08 13:13:19 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:13:19 | INFO | fairseq.tasks.translation | example reference: có lẽ nguyên tắc sát sườn nhất với chúng ta là nguyên tắc của linus torvalds, người tiên phong cho nguồn mở đó là ý tưởng của & quot; hãy lười như một con cáo. & quot;\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:  76%|████▌ | 35/46 [06:45<01:34,  8.63s/it]\u001b[A2020-12-08 13:13:28 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:13:28 | INFO | fairseq.tasks.translation | example reference: tôi muốn cháu trai daniel của tôi và bạn của nó cùng thế hệ của nó trên toàn thế giới biết được câu chuyện lịch sử to lớn này và hiểu nó một cách sâu sắc cho chúng hiểu rằng cả những thách thức mà chúng ta đang đối mặt và cả những cơ hội mà chúng ta có\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:  78%|████▋ | 36/46 [06:54<01:27,  8.71s/it]\u001b[A2020-12-08 13:13:36 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:13:36 | INFO | fairseq.tasks.translation | example reference: một điều nữa để nghĩ đến là thật vinh dự làm sao cho một chính trị gia như tôi được có buổi nói chuyện tại ted, đặc biệt là ở đây tại vương quốc anh, nơi mà danh tiếng và uy tín của chính trị đã chìm sâu với những xì-căng-đan.\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:  80%|████▊ | 37/46 [07:02<01:17,  8.57s/it]\u001b[A2020-12-08 13:13:44 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:13:44 | INFO | fairseq.tasks.translation | example reference: trong ted video lưu trữ từ năm 1998, paralympic vận động viên aimee mullins nói về sự nghiệp kỷ lục của cô như một vận động viên điền kinh, và về đôi chân giả tuyệt vời đã giúp cô băng qua vạch kết thúc.\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:  83%|████▉ | 38/46 [07:11<01:08,  8.53s/it]\u001b[A2020-12-08 13:13:52 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:13:52 | INFO | fairseq.tasks.translation | example reference: ví dụ, giữa anh em, các tổ chức anh em, hôi nữ sinh... như & quot; gia đình loài người, & quot; bạn cố gắng khiến những người không phải ruột rà dùng kiểu quan hệ thường chỉ phù hợp với bà con thân thuộc.\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:  85%|█████ | 39/46 [07:19<00:58,  8.31s/it]\u001b[A2020-12-08 13:13:59 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:13:59 | INFO | fairseq.tasks.translation | example reference: chúng ta đang xây dựng những kính thiên văn để tìm ra những đe doạ. đó là một bước đầu tiên tuyệt vời, vậy thì bước thứ hai là gì? bước thứ hai là nếu chúng ta nhìn thấy một cái nào hướng về chúng ta, chúng ta phải chặn nó. chúng ta chặn bằng cách nào?\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:  87%|█████▏| 40/46 [07:25<00:46,  7.80s/it]\u001b[A2020-12-08 13:14:06 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:14:06 | INFO | fairseq.tasks.translation | example reference: mỗi cơn bão càn quét qua bầu khí quyển, cuốn đi bụi, muội than, vi hoá chất, và thả lại những chất đó trên đống tuyết năm này qua năm khác, thiên niên kỉ này qua thiên niên kỉ khác, tạo nên một dạng bảng tuần hoàn hoá học mà tại thời điểm này dày hơn 11000 feet.\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:  89%|█████▎| 41/46 [07:32<00:37,  7.53s/it]\u001b[A2020-12-08 13:14:14 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:14:14 | INFO | fairseq.tasks.translation | example reference: kể cả khi bạn không biết các phần đó là gì, phân vân chúng có thể dùng cho việc gì thì cũng là một sự luyện tập rất tốt cho trẻ để có một cái nhìn về việc là chúng có thể tháo đồ vật ra, và cho dù nó có phức tạp cỡ nào, thì chúng có thể hiểu một phần của đồ vật và điều đó nghĩa là cuối cùng, chúng có thể hiểu tất cả,\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:  91%|█████▍| 42/46 [07:41<00:31,  7.84s/it]\u001b[A2020-12-08 13:14:22 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:14:22 | INFO | fairseq.tasks.translation | example reference: và tôi đã nhận được rất nhiều sự chỉ trích trên mạng sau khi dự án kichstarter của tôi phát triển để tiếp tục những cuộc quyên góp điên rồ của tôi, đặc biệt để mời các nhạc sĩ những người là người hâm mộ nếu họ muốn tham gia cùng chúng tôi trên sân khấu một vài bài hát được đổi với tình yêu và những chiếc vé và bia, và đây là một hình ảnh bị sửa đổi được dựng lên về tôi trên một trang web.\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:  93%|█████▌| 43/46 [07:48<00:23,  7.79s/it]\u001b[A2020-12-08 13:14:29 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:14:29 | INFO | fairseq.tasks.translation | example reference: đại khái là tôi đã chắt lọc được một triết lý sống rất khó giải thích và phức tạp mà tôi sẽ không đi vào ở đây, tại nó hơi sâu quá đối với tất cả mọi người ở đây, nhưng -- triết lý đó là về những gì làm cho các trang web nổi tiếng và, các bạn biết đấy, thật là -- thật là đáng tiếc vì tôi không được có thêm thời gian.\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:  96%|█████▋| 44/46 [07:55<00:14,  7.47s/it]\u001b[A2020-12-08 13:14:37 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:14:37 | INFO | fairseq.tasks.translation | example reference: chú chó đến với tôi vào lúc chúng tôi đang tranh cãi về một thiết bị xử lý rác lớn cho cảng sông đông, bất chấp thực tế là khu vực nhỏ này của thành phố new york ¾ đã xử lý hơn 40% lượng rác thải tiêu dùng của toàn thành phố. thành phố đã có một nhà máy ép xử lý nước thải, một nhà máy xử lý bùn thải, bốn nhà máy điện, và khu phân phối lương thực lớn nhất thế giới, cũng như các ngành công nghiệp khác đã khiến hơn 60000 chuyến xe tải diesel đến thành phố mỗi tuần.\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:  98%|█████▊| 45/46 [08:03<00:07,  7.63s/it]\u001b[A2020-12-08 13:14:40 | INFO | fairseq.tasks.translation | example hypothesis: và chúng ta có thể làm việc.\n",
      "2020-12-08 13:14:40 | INFO | fairseq.tasks.translation | example reference: chúng tôi đóng cả tàu chiến và tàu tuần dương cho nữ hoàng, tàu chở dầu cho onassis và tất cả các loại tàu khác chúng tôi đóng tàu có trọng tải lớn nhất từng có trên thế giới đời đáng sống là trong xưởng đóng tàu thép trong xưởng, tâm hồn cũng sắt mới ngày nào chỉ là vỏ sắt đến hôm nay đã một con tàu đời chúng tôi rồi sẽ ra sao nếu ai đó mang xưởng này đi bán chỉ nơi đây đời tôi đáng sống đã quyết từ nay sẽ viết về người khác chứ không về chính mình, điều trớ trêu nữa là đôi khi bạn bày tỏ về con người mình nhiều hơn ý định.\n",
      "\n",
      "epoch 001 | valid on 'valid' subset: 100%|██████| 46/46 [08:06<00:00,  6.34s/it]\u001b[A\n",
      "                                                                                \u001b[A2020-12-08 13:14:40 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.832 | nll_loss 6.95 | ppl 123.66 | bleu 0.31 | wps 279.3 | wpb 2861.9 | bsz 108 | num_updates 1398\n",
      "2020-12-08 13:14:40 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2020-12-08 13:14:44 | INFO | fairseq.checkpoint_utils | saved checkpoint ed-iwslt-checkpoints/fconv_wmt_en_vi/checkpoint1.pt (epoch 1 @ 1398 updates, score 0.31) (writing took 3.7917731499983347 seconds)\n",
      "2020-12-08 13:14:44 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
      "2020-12-08 13:14:44 | INFO | train | epoch 001 | loss 9.013 | nll_loss 8.352 | ppl 326.84 | wps 275.6 | ups 0.13 | wpb 2114.5 | bsz 78.2 | num_updates 1398 | lr 0.000267452 | gnorm 1.169 | train_wall 10203 | wall 10727\n",
      "epoch 002:   0%|                                       | 0/1398 [00:00<?, ?it/s]2020-12-08 13:14:44 | INFO | fairseq.trainer | begin training epoch 2\n",
      "epoch 002:   9%| | 128/1398 [14:29<2:31:08,  7.14s/it, loss=7.854, nll_loss=7.02^C\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p \"ed-iwslt-checkpoints/fconv_wmt_en_vi\"\n",
    "!CUDA_VISIBLE_DEVICES=0 fairseq-train \"ed-iwslt-data-bin/tokenized.en-vi\" \\\n",
    "    --arch transformer --share-decoder-input-output-embed \\\n",
    "    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\\n",
    "    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 400 \\\n",
    "    --dropout 0.3 --weight-decay 0.0001 \\\n",
    "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
    "    --max-tokens 4096 \\\n",
    "    --eval-bleu \\\n",
    "    --eval-bleu-args '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}' \\\n",
    "    --eval-bleu-detok moses \\\n",
    "    --eval-bleu-remove-bpe \\\n",
    "    --eval-bleu-print-samples \\\n",
    "    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \\\n",
    "    --save-dir \"ed-iwslt-checkpoints/fconv_wmt_en_vi\" \\\n",
    "    --max-epoch 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 920,
     "status": "ok",
     "timestamp": 1606188005510,
     "user": {
      "displayName": "Chinh hoang trung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64",
      "userId": "05604119531382760831"
     },
     "user_tz": -420
    },
    "id": "xvo9_A3MK6p5",
    "outputId": "1476590f-7183-4b47-f289-2095a2a127b8"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/home/chinh/clc_fairseq\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 802,
     "status": "ok",
     "timestamp": 1606292073968,
     "user": {
      "displayName": "Chinh hoang trung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64",
      "userId": "05604119531382760831"
     },
     "user_tz": -420
    },
    "id": "6HHzwi1G_UMr",
    "outputId": "155022f5-16cf-4d08-a7e9-72ad85c535b8",
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cal ideas may be needed , and i think that we may need one or two ideas that initially seem crazy before we can come to grips with consciousness scientifically .\n",
      "T-772\tđối mặt với một thứ dị thường như thế này , sẽ cần những ý tường cấp tiến và thôi nghĩ rằng chúng ta sẽ cần một hoặc hai ý tướng ban đầu , nghe có vẻ điên khùng trước khi chúng ta hiểu biết một cách khoa học .\n",
      "H-772\t-2.3584330081939697\tvà chúng ta có thể làm việc .\n",
      "D-772\t-2.3584330081939697\tvà chúng ta có thể làm việc .\n",
      "P-772\t-2.3632 -4.3767 -0.9269 -2.3555 -0.7019 -3.8860 -2.2792 -4.1781 -0.1584\n",
      "S-19\tit acts to maximize future freedom of action , or keep options open , with some strength t , with the diversity of possible accessible futures , s , up to some future time horizon , tau .\n",
      "T-19\tnó hành động để tối đa hóa tự do hành động tương lai , hoặc giữ cho các lựa chọn được để ngỏ , với một cường độ t , với sự đa dạng của các tương lai có thể đạt tới , s trong một ngưỡng thời gian tương lai nào đó , tau .\n",
      "H-19\t-2.3584325313568115\tvà chúng ta có thể làm việc .\n",
      "D-19\t-2.3584325313568115\tvà chúng ta có thể làm việc .\n",
      "P-19\t-2.3632 -4.3767 -0.9269 -2.3555 -0.7019 -3.8860 -2.2792 -4.1781 -0.1584\n",
      "S-936\tultimately , we need to work together as communities , as governments and as businesses to really change this culture of ours so that our kids grow up valuing their whole selves , valuing individuality , diversity , inclusion .\n",
      "T-936\trốt cục , chúng ta cần chung tay với nhau cũng như với cộng đồng , chính phủ , và các doanh nghiệp để thực sự thay đổi văn hóa này của chúng ta để con em chúng ta lớn lên coi trọng chính bản thân mình , coi trọng cá nhân , tính cá nhân sự đa dạng .\n",
      "H-936\t-2.3584327697753906\tvà chúng ta có thể làm việc .\n",
      "D-936\t-2.3584327697753906\tvà chúng ta có thể làm việc .\n",
      "P-936\t-2.3632 -4.3767 -0.9269 -2.3555 -0.7019 -3.8860 -2.2792 -4.1781 -0.1584\n",
      "S-695\ti don &amp; apos ; t know what it &amp; apos ; s like to be gay , but i &amp; apos ; m well acquainted with being judged for something that &amp; apos ; s beyond my control .\n",
      "T-695\tvơ ́ i như <<unk>> ng kinh nghiê ̣ m va <<unk>> tương ta ́ c trong cuô ̣ c sô ́ ng thâ ̣ t . tôi không biê ́ t ngươ <<unk>> i đô <<unk>> ng ti ́ nh la <<unk>> như thê ́ na <<unk>> o , nhưng tôi hiểu ca <<unk>> m gia ́ c bi ̣ đa ́ nh gia ́\n",
      "H-695\t-2.3584325313568115\tvà chúng ta có thể làm việc .\n",
      "D-695\t-2.3584325313568115\tvà chúng ta có thể làm việc .\n",
      "P-695\t-2.3632 -4.3767 -0.9269 -2.3555 -0.7019 -3.8860 -2.2792 -4.1781 -0.1584\n",
      "S-699\tshe looked at me with the weary eyes of someone who had experienced enough dogmatism to last a lifetime , and said , &amp; quot ; i &amp; apos ; m tired of hating people . &amp; quot ;\n",
      "T-699\tva <<unk>> ba <<unk>> no ́ i vơ ́ i tôi mô ̣ t điê <<unk>> u ma <<unk>> tôi se <<unk>> luôn nhơ ́ ma <<unk>> i trong tim . bà nhi <<unk>> n tôi vơ ́ i đôi mă ́ t mê ̣ t mo <<unk>> i cu <<unk>> a mô ̣ t ngươ <<unk>> i tư <<unk>> ng tra <<unk>> i qua qua ́ nhiê <<unk>> u chu <<unk>> nghi <<unk>> a gia ́ o ly ́ , va <<unk>> no ́ i :\n",
      "H-699\t-2.3584327697753906\tvà chúng ta có thể làm việc .\n",
      "D-699\t-2.3584327697753906\tvà chúng ta có thể làm việc .\n",
      "P-699\t-2.3632 -4.3767 -0.9269 -2.3555 -0.7019 -3.8860 -2.2792 -4.1781 -0.1584\n",
      "S-149\ti began to try different mixtures , and i was blown away by how tiny changes in dosages dramatically changed my sense of self , my sense of who i was , my thinking , my behavior towards people .\n",
      "T-149\ttôi bắt đầu thử pha trộn khác đi và thật kinh ngạc chỉ một thay đổi nhỏ về liều lượng cũng có thể thay đổi ghê gớm cảm nhận của tôi về bản thân , cách suy nghĩ và cách cư xử với người khác .\n",
      "H-149\t-2.3584327697753906\tvà chúng ta có thể làm việc .\n",
      "D-149\t-2.3584327697753906\tvà chúng ta có thể làm việc .\n",
      "P-149\t-2.3632 -4.3767 -0.9269 -2.3555 -0.7019 -3.8860 -2.2792 -4.1781 -0.1584\n",
      "S-942\twhat would it mean for her if she were freed from that voice of her inner critic , nagging her to have longer legs , thinner thighs , smaller stomach , shorter feet ?\n",
      "T-942\tđiều có ý nghĩa gì với cô ấy nếu cô ấy được giải phóng khỏi tiếng nói nội tâm đang phê phán , quở trách bản thân để có chân dài hơn , đùi thon hơn dạ dày nhỏ hơn , bàn chân ngắn hơn ?\n",
      "H-942\t-2.3584327697753906\tvà chúng ta có thể làm việc .\n",
      "D-942\t-2.3584327697753906\tvà chúng ta có thể làm việc .\n",
      "P-942\t-2.3632 -4.3767 -0.9269 -2.3555 -0.7019 -3.8860 -2.2792 -4.1781 -0.1584\n",
      " 86%|██████████████████████████████▊     | 6/7 [01:35<00:15, 15.49s/it, wps=101]S-1071\tand it means that a building doesn &amp; apos ; t have to be beautiful to be lovable , like this ugly little building in spain , where the architects dug a hole , packed it with hay , and then poured concrete around it , and when the concrete dried , they invited someone to come and clean that hay out so that all that &amp; apos ; s left when it &amp; apos ; s done is this hideous little room that &amp; apos ; s filled with the imprints and scratches of how that place was made , and that becomes the most sublime place to watch a spanish sunset .\n",
      "T-1071\tvà nó có nghĩa là một toà nhà không cần phải đẹp , phải được yêu thích , như ngôi nhà nhỏ bé xấu xí này ở tây ban nha , nơi mà các kiến trúc sư đã đào một cái lỗ , lớp nó với rơm , và sau đó đổ vữa xung quanh nó , và khi vữa khô lại , họ mời một ai đó đến và làm sạch tất cả rơm rạ , để khi tất cả những thứ đó kết thúc , để lại là căn phòng nhỏ bé gồ ghề này , chứa đầy những dấu tích và vết cào xước của quá trình tạo ra nơi này , và nó trở thành một nơi tuyệt vời để ngắm nhìn hoàng hôn tây ban nha .\n",
      "H-1071\t-2.3584325313568115\tvà chúng ta có thể làm việc .\n",
      "D-1071\t-2.3584325313568115\tvà chúng ta có thể làm việc .\n",
      "P-1071\t-2.3632 -4.3767 -0.9269 -2.3555 -0.7019 -3.8860 -2.2792 -4.1781 -0.1584\n",
      "S-114\ti could go back to my girlfriend and my gay-loving table and mock their responses , chastise their unworldliness and their inability to jump through the politically correct gay hoops i had brought with me , or i could empathize with them and realize that that was maybe one of the hardest things they had ever done , that starting and having that conversation was them coming out of their closets .\n",
      "T-114\ttôi có thể quay trở lại chỗ bạn gái mình quay lại bàn những người bạn đồng tính của mình và bắt chước phản ứng của họ , vẻ bộ thanh cao và sự bất lực của họ khi cố gắng tránh từ ngữ thiếu tôn trọng người đồng tính khi nói chuyện với tôi hoặc tôi có thể thông cảm với họ và nhận ra rằng đây có lẽ là một trong những vấn đề khó khăn nhất , mà họ từng gặp , rằng việc họ bắt đầu những cuộc trò chuyện chính là lúc họ bước ra khỏi chiếc tủ của mình .\n",
      "H-114\t-2.3584330081939697\tvà chúng ta có thể làm việc .\n",
      "D-114\t-2.3584330081939697\tvà chúng ta có thể làm việc .\n",
      "P-114\t-2.3632 -4.3767 -0.9269 -2.3555 -0.7019 -3.8860 -2.2792 -4.1781 -0.1584\n",
      "S-1049\twe proposed a building that was audacious , that was different than any of the forms that the community was used to , and we were scared and our client was scared and the community was scared , so we created a series of photorealistic renderings that we put onto facebook and we put onto instagram , and we let people start to do what they do : share it , comment , like it , hate it .\n",
      "T-1049\tchúng ta đã đề xuất một toà nhà rất táo bạo , rất khác biệt với tất cả những khuôn mẫu mà cộng đồng vốn quen thuộc , và chúng tôi lo lắng và khách hàng của chúng tôi cũng cảm thấy lo lắng và cộng đồng cũng lo lắng , nên chúng tôi đã tạo ra một loạt những bản dựng hình ảnh như thật và chúng tôi đăng lên facebook và chúng tôi đăng lên instagram , và chúng tôi để mọi người bắt đầu làm điều mà họ làm : chia sẻ nó , bình luận , thích nó , ghét nó .\n",
      "H-1049\t-2.3584325313568115\tvà chúng ta có thể làm việc .\n",
      "D-1049\t-2.3584325313568115\tvà chúng ta có thể làm việc .\n",
      "P-1049\t-2.3632 -4.3767 -0.9269 -2.3555 -0.7019 -3.8860 -2.2792 -4.1781 -0.1584\n",
      "S-9\tyou observe that , over the course of the millennia , earth is continually bombarded with asteroids up until a point , and that at some point , corresponding roughly to our year , 2000 ad , asteroids that are on a collision course with the earth that otherwise would have collided mysteriously get deflected or they detonate before they can hit the earth .\n",
      "T-9\tquý vị sẽ thấy rằng , qua hàng thiên nhiên kỉ , trái đất đã liên tục va chạm với những thiên thạch cho đến một thời điểm tại đó , ứng những năm của chúng ta , khoảng 2000 năm sau cn thời điểm những thiên thạch đang bay theo hướng sắp va vào trái đất hẳn sẽ va vào trái đất thì chợt bị làm chệch hướng hoặc nổ tung trước khi va .\n",
      "H-9\t-2.3584327697753906\tvà chúng ta có thể làm việc .\n",
      "D-9\t-2.3584327697753906\tvà chúng ta có thể làm việc .\n",
      "P-9\t-2.3632 -4.3767 -0.9269 -2.3555 -0.7019 -3.8860 -2.2792 -4.1781 -0.1584\n",
      "S-362\ti &amp; apos ; m wondering what you would say , especially to parents , but in a more broad way , to friends , to family , to anyone who finds themselves encountering a child or a person who is struggling with and uncomfortable with a gender that &amp; apos ; s being assigned them , what might you say to the family members of that person to help them become good and caring and kind family members to them ?\n",
      "T-362\tbạn sẽ nói gì với các bậc cha mẹ , xa hơn nữa , là bạn bè , gia đình , hay bất cứ ai đang tìm cách đối diện với một đứa trẻ hay người nào đó gặp khó khăn về giới tính của mình. bạn sẽ nói gì với những người trong gia đình của họ để giúp những người này cảm thấy thoải mái , quan tâm và đối xử tử tế với những người đó ?\n",
      "H-362\t-2.3584322929382324\tvà chúng ta có thể làm việc .\n",
      "D-362\t-2.3584322929382324\tvà chúng ta có thể làm việc .\n",
      "P-362\t-2.3632 -4.3767 -0.9269 -2.3555 -0.7019 -3.8860 -2.2792 -4.1781 -0.1584\n",
      "S-140\tand we know it &amp; apos ; s hard but we need you out here , no matter what your walls are made of , because i guarantee you there are others peering through the keyholes of their closets looking for the next brave soul to bust a door open , so be that person and show the world that we are bigger than our closets and that a closet is no place for a person to truly live .\n",
      "T-140\tvà chúng tôi biết việc này là khó nhưng chúng tôi cần bạn bước ra khỏi đó , cho dù chiếc tủ của bạn được làm từ thứ gì , bởi vì tôi cam đoan với bạn rằng có những người khác đang nhòm qua lỗ khóa chiếc tủ của họ để tìm kiếm linh hồn dũng cảm tiếp theo lao ra khỏi cánh cửa tủ , để trở thành con người đó và để cho thế giới này thấy rằng chúng ta to lớn hơn cả những chiếc tủ của mình rằng một chiếc tủ không phải là nơi mà một con người thực sự sống .\n",
      "H-140\t-2.3584325313568115\tvà chúng ta có thể làm việc .\n",
      "D-140\t-2.3584325313568115\tvà chúng ta có thể làm việc .\n",
      "P-140\t-2.3632 -4.3767 -0.9269 -2.3555 -0.7019 -3.8860 -2.2792 -4.1781 -0.1584\n",
      "S-330\tso from 15 to 17 years old , i joined the most prestigious pageant to the pageant where it &amp; apos ; s at the back of the truck , literally , or sometimes it would be a pavement next to a rice field , and when it rains -- it rains a lot in the philippines -- the organizers would have to move it inside someone &amp; apos ; s house .\n",
      "T-330\tcho nên , từ 15 đến 17 tuổi , tôi tham gia từ những cuộc thi uy tín nhất đến những cuộc thi ở thùng xe tải , theo đúng nghĩa đen hay đôi khi là ở lề đường cạnh đồng lúa , và ở philippines , khi trời mưa mưa rất nhiều , những người tổ chức phải di chuyển vào trong nhà của ai đó .\n",
      "H-330\t-2.3584327697753906\tvà chúng ta có thể làm việc .\n",
      "D-330\t-2.3584327697753906\tvà chúng ta có thể làm việc .\n",
      "P-330\t-2.3632 -4.3767 -0.9269 -2.3555 -0.7019 -3.8860 -2.2792 -4.1781 -0.1584\n",
      "S-36\tjust as some animals can use objects in their environments as tools to reach into narrow spaces , here we see that entropica , again on its own initiative , was able to move a large disk representing an animal around so as to cause a small disk , representing a tool , to reach into a confined space holding a third disk and release the third disk from its initially fixed position .\n",
      "T-36\thệt như một số động vật có thể dùng các vật thể trong môi trường làm công cụ để vươn ra trong một không gian hẹp đây ta thấy máy entropica , vẫn dựa vào tài trí của mình , có khả năng di chuyển một đĩa lớn tượng trưng cho một con vật dịch chuyển đó khiến cho một đĩa nhỏ , tượng trưng cho một công cụ , vươn ra trong không gian giới hạn nắm lấy cái đĩa thứ ba và thả chiếc đĩa thứ ba từ vị trí cố định ban đầu của nó .\n",
      "H-36\t-2.3584327697753906\tvà chúng ta có thể làm việc .\n",
      "D-36\t-2.3584327697753906\tvà chúng ta có thể làm việc .\n",
      "P-36\t-2.3632 -4.3767 -0.9269 -2.3555 -0.7019 -3.8860 -2.2792 -4.1781 -0.1584\n",
      "S-239\tladies and gentlemen , this plight of millions of women could be changed if we think differently , if women and men think differently , if men and women in the tribal and patriarchal societies in the developing countries , if they can break a few norms of family and society , if they can abolish the discriminatory laws of the systems in their states , which go against the basic human rights of the women .\n",
      "T-239\tkính thưa quý bà và quý ông cảnh ngộ nghiệt ngã mà hàng triệu phụ nữ gặp phải này có thể được thay đổi nếu chúng ta suy nghĩ khác đi , nếu phụ nữ và nam giới suy nghĩ khác đi , nếu đàn ông và phụ nữ trong xã hội phụ hệ và mang tính bộ lạc ở các nước đang phát triển , nếu họ có thể phá vỡ luật lệ về gia đình và xã hội , nếu họ có thể bãi bỏ luật phân biệt đối xử trong hệ thống xã hội của mình , những thứ mà đi ngược lại các nhân quyền cơ bản của phụ nữ .\n",
      "H-239\t-2.3584320545196533\tvà chúng ta có thể làm việc .\n",
      "D-239\t-2.3584320545196533\tvà chúng ta có thể làm việc .\n",
      "P-239\t-2.3632 -4.3767 -0.9269 -2.3555 -0.7019 -3.8860 -2.2792 -4.1781 -0.1584\n",
      "S-56\tfinally , richard feynman , famous physicist , once wrote that if human civilization were destroyed and you could pass only a single concept on to our descendants to help them rebuild civilization , that concept should be that all matter around us is made out of tiny elements that attract each other when they &amp; apos ; re far apart but repel each other when they &amp; apos ; re close together .\n",
      "T-56\tđiểm cuối cùng , richard feynman , một nhà vật lý nổi tiếng , đã viết rằng nếu văn minh loài người bị hủy diệt và bạn chỉ còn cơ hội để lại một lời nhắn duy nhất cho con cháu mình hòng giúp chúng xây dựng lại nền văn minh , thì lời nhắn ấy là tất cả những thứ quanh ta được làm nên bởi các nguyên tố nhỏ bé nguyên tố đó hấp dẫn nhau khi chúng ở xa nhau nhưng lại đẩy nhau khi chúng ở gần nhau .\n",
      "H-56\t-2.3584325313568115\tvà chúng ta có thể làm việc .\n",
      "D-56\t-2.3584325313568115\tvà chúng ta có thể làm việc .\n",
      "P-56\t-2.3632 -4.3767 -0.9269 -2.3555 -0.7019 -3.8860 -2.2792 -4.1781 -0.1584\n",
      "S-12\tbut if you &amp; apos ; re an alien race who doesn &amp; apos ; t know any of this , doesn &amp; apos ; t have any concept of earth intelligence , you &amp; apos ; d be forced to put together a physical theory that explains how , up until a certain point in time , asteroids that would demolish the surface of a planet mysteriously stop doing that .\n",
      "T-12\tnhưng nếu quý vị là một người ngoài hành tinh không hiểu về chuyện này , không có bất kì khái niệm gì về trí thông minh trái đất , quý vị sẽ buộc phải tiếp nhận một giả thuyết vật lí giải thích cách sao vào thời điểm nào đó , những thiên thạch lẽ ra phá hủy bề mặt của một hành tinh lại dừng lại cách bí ẩn .\n",
      "H-12\t-2.3584327697753906\tvà chúng ta có thể làm việc .\n",
      "D-12\t-2.3584327697753906\tvà chúng ta có thể làm việc .\n",
      "P-12\t-2.3632 -4.3767 -0.9269 -2.3555 -0.7019 -3.8860 -2.2792 -4.1781 -0.1584\n",
      "S-827\tnow , i don &amp; apos ; t know if this theory is right , but it &amp; apos ; s actually perhaps the leading theory right now in the science of consciousness , and it &amp; apos ; s been used to integrate a whole range of scientific data , and it does have a nice property that it is in fact simple enough you can write it on the front of a t-shirt .\n",
      "T-827\tbây giờ , tôi không biết nếu học thuyết na <<unk>> y là đúng , nhưng nó sẽ có thể dẫn đến một học thuyết trong khoa học về ý thức , và nó được dùng để nhập những nhánh thông tin của dữ liệu khoa học , và nó có một đặc tính tốt thứ mà trên thực tế đủ đơn giản để bạn có thể viết chúng lên mặt trước của áo\n",
      "H-827\t-2.3584322929382324\tvà chúng ta có thể làm việc .\n",
      "D-827\t-2.3584322929382324\tvà chúng ta có thể làm việc .\n",
      "P-827\t-2.3632 -4.3767 -0.9269 -2.3555 -0.7019 -3.8860 -2.2792 -4.1781 -0.1584\n",
      "S-7\tpretend that you &amp; apos ; re an alien race that doesn &amp; apos ; t know anything about earth biology or earth neuroscience or earth intelligence , but you have amazing telescopes and you &amp; apos ; re able to watch the earth , and you have amazingly long lives , so you &amp; apos ; re able to watch the earth over millions , even billions of years .\n",
      "T-7\tgiả sử quý vị thuộc một chủng người ngoài hành tinh không biết gì về sinh học trái đất , về khoa thần kinh , hay trí thông minh trái đât , nhưng có chiếc kính viễn vọng rất tuyệt giúp quan sát trái đất , và đời quý vị rất dài nên có thể quan sát hàng triệu , thậm chí hàng tỉ năm .\n",
      "H-7\t-2.3584325313568115\tvà chúng ta có thể làm việc .\n",
      "D-7\t-2.3584325313568115\tvà chúng ta có thể làm việc .\n",
      "P-7\t-2.3632 -4.3767 -0.9269 -2.3555 -0.7019 -3.8860 -2.2792 -4.1781 -0.1584\n",
      "S-365\ti mean , we &amp; apos ; re all assigned gender at birth , so what i &amp; apos ; m trying to do is to have this conversation that sometimes that gender assignment doesn &amp; apos ; t match , and there should be a space that would allow people to self-identify , and that &amp; apos ; s a conversation that we should have with parents , with colleagues .\n",
      "T-365\tchúng ta được mặc định giới tinh ngay từ lúc sinh ra , cho nên điều mà tôi cố gắng làm là tạo ra những cuộc đối thoại rằng đôi khi giới tính hiện tại cũng không hoàn toàn đúng , cần có một khoảng trống cho phép con người tự xác định lại chính bản thân mình , và chúng ta cần những cuộc đối thoại như vậy với cha mẹ , bạn bè .\n",
      "H-365\t-2.3584325313568115\tvà chúng ta có thể làm việc .\n",
      "D-365\t-2.3584325313568115\tvà chúng ta có thể làm việc .\n",
      "P-365\t-2.3632 -4.3767 -0.9269 -2.3555 -0.7019 -3.8860 -2.2792 -4.1781 -0.1584\n",
      "S-929\tthe second is media and celebrity culture , then how to handle teasing and bullying , the way we compete and compare with one another based on looks , talking about appearance — some people call this &amp; quot ; body talk &amp; quot ; or &amp; quot ; fat talk &amp; quot ; — and finally , the foundations of respecting and looking after yourself .\n",
      "T-929\tthứ hai là thông tin đại chúng và văn hóa thần tượng cách xử lý việc trêu chọc và bắt nạt , cách chúng ta thi đua , so sánh với người khác dựa vào vẻ ngoài nói về vẻ ngoài - vài người gọi đây là &amp; quot ; cơ thể lên tiếng &amp; quot ; hoặc &amp; quot ; mỡ lên tiếng &amp; quot ; và cuối cùng , nền tảng của việc tôn trọng và chăm sóc bản thân .\n",
      "H-929\t-2.3584327697753906\tvà chúng ta có thể làm việc .\n",
      "D-929\t-2.3584327697753906\tvà chúng ta có thể làm việc .\n",
      "P-929\t-2.3632 -4.3767 -0.9269 -2.3555 -0.7019 -3.8860 -2.2792 -4.1781 -0.1584\n",
      "S-789\tin the 19th century , maxwell figured out that you can &amp; apos ; t explain electromagnetic phenomena in terms of the existing fundamentals — space , time , mass , newton &amp; apos ; s laws — so he postulated fundamental laws of electromagnetism and postulated electric charge as a fundamental element that those laws govern .\n",
      "T-789\ttrong thế kỉ 19 , maxwell đã cho rằng bạn không thể giải thích hiện tượng điện từ bằng những khái niệm cơ bản như không gian , thời gian , khối lượng , đinh luật newton vì thế ông ấy đã đặt ra định luật cơ bản về điện từ và đặt ra sự tích điện như là một nguyên tố cơ bản theo những quy luật đã có này .\n",
      "H-789\t-2.3584325313568115\tvà chúng ta có thể làm việc .\n",
      "D-789\t-2.3584325313568115\tvà chúng ta có thể làm việc .\n",
      "P-789\t-2.3632 -4.3767 -0.9269 -2.3555 -0.7019 -3.8860 -2.2792 -4.1781 -0.1584\n",
      "2020-12-08 13:35:07 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
      "2020-12-08 13:35:07 | INFO | fairseq_cli.generate | Translated 1080 sentences (9720 tokens) in 86.3s (12.52 sentences/s, 112.64 tokens/s)\n",
      "Generate test with beam=5: BLEU4 = 0.18, 25.9/3.6/0.5/0.1 (BP=0.126, ratio=0.325, syslen=8640, reflen=26566)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "!mkdir -p ed-iwslt-data-bin/fconv_wmt_en_vi\n",
    "!fairseq-generate \\\n",
    "    ed-iwslt-data-bin/tokenized.en-vi/ \\\n",
    "    --path ed-iwslt-checkpoints/fconv_wmt_en_vi/checkpoint_best.pt \\\n",
    "    --beam 5 --remove-bpe | tee ed-iwslt-data-bin/fconv_wmt_en_vi/gen.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2IecrmTbBni"
   },
   "source": [
    "Compute BLEU score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "KAHR1vuYbC4R"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Namespace(ignore_case=False, order=4, ref='ed-iwslt-data-bin/fconv_wmt_en_vi/gen.out.ref', sacrebleu=False, sentence_bleu=False, sys='ed-iwslt-data-bin/fconv_wmt_en_vi/gen.out.sys')\n",
      "BLEU4 = 0.18, 25.9/3.7/0.5/0.1 (BP=0.126, ratio=0.325, syslen=8640, reflen=26566)\n"
     ]
    }
   ],
   "source": [
    "!grep ^H ed-iwslt-data-bin/fconv_wmt_en_vi/gen.out | cut -f3- > ed-iwslt-data-bin/fconv_wmt_en_vi/gen.out.sys\n",
    "!grep ^T ed-iwslt-data-bin/fconv_wmt_en_vi/gen.out | cut -f2- > ed-iwslt-data-bin/fconv_wmt_en_vi/gen.out.ref\n",
    "!fairseq-score --sys ed-iwslt-data-bin/fconv_wmt_en_vi/gen.out.sys --ref ed-iwslt-data-bin/fconv_wmt_en_vi/gen.out.ref\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BLEU4 = 0.18, quá tệ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cô ấy đang làm việc ở trường học .\n"
     ]
    }
   ],
   "source": [
    "from fairseq.models.transformer import TransformerModel\n",
    "model = TransformerModel.from_pretrained(\n",
    "  'iwslt-checkpoints-v2/fconv_wmt_en_vi',\n",
    "  checkpoint_file='checkpoint_best.pt',\n",
    "  bpe='subword_nmt',\n",
    "  bpe_codes = 'iwslt-tokenized.en-vi/code'\n",
    ")\n",
    "print(model.translate('I am going to school'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Fairseq - 0622 en-vi TED data v1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}