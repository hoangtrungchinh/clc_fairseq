{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHBsw0sUrGaQ"
   },
   "source": [
    "# **HOW TO TRAIN NEW MODEL (En to Vi)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQpoxG9RKlI-"
   },
   "source": [
    "Phiên bản V3 nhằm chạy thử model TED anh - việt với các đặc điểm:\n",
    "\n",
    "1 - Chạy  1 epoch\n",
    "\n",
    "2 - Thực hiện trên máy local\n",
    "\n",
    "3 - Tiền xử lý chỉ có lower case mà thôi, sau đó là áp dụng bpe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPLcxMFbs29E"
   },
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning Moses github repository (for tokenization scripts)...\n",
      "fatal: destination path 'mosesdecoder' already exists and is not an empty directory.\n",
      "Cloning Subword NMT repository (for BPE pre-processing)...\n",
      "fatal: destination path 'subword-nmt' already exists and is not an empty directory.\n",
      "Downloading data from https://github.com/hoangtrungchinh/clc_data/raw/master/en_vi_iwslt.tar.gz...\n",
      "--2020-12-02 10:17:50--  https://github.com/hoangtrungchinh/clc_data/raw/master/en_vi_iwslt.tar.gz\n",
      "Resolving github.com (github.com)... 192.30.255.112\n",
      "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/hoangtrungchinh/clc_data/master/en_vi_iwslt.tar.gz [following]\n",
      "--2020-12-02 10:17:51--  https://raw.githubusercontent.com/hoangtrungchinh/clc_data/master/en_vi_iwslt.tar.gz\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.192.133, 151.101.128.133, 151.101.64.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.192.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9044100 (8,6M) [application/octet-stream]\n",
      "Saving to: ‘en_vi_iwslt.tar.gz.2’\n",
      "\n",
      "en_vi_iwslt.tar.gz. 100%[===================>]   8,62M  2,03MB/s    in 4,6s    \n",
      "\n",
      "2020-12-02 10:17:56 (1,87 MB/s) - ‘en_vi_iwslt.tar.gz.2’ saved [9044100/9044100]\n",
      "\n",
      "Data successfully downloaded.\n",
      "mkdir: cannot create directory ‘en-vi’: File exists\n",
      "IWSLT15.TED.tst2013.en-vi.en\n",
      "IWSLT15.TED.tst2013.en-vi.vi\n",
      "IWSLT15.TED.tst2012.en-vi.en\n",
      "IWSLT15.TED.tst2012.en-vi.vi\n",
      "train.en\n",
      "train.vi\n",
      "IWSLT15.TED.tst2015.en-vi.en\n",
      "IWSLT15.TED.tst2015.en-vi.vi\n",
      "pre-processing train data...\n",
      "\n",
      "\n",
      "pre-processing valid/test data...\n",
      "\n",
      "\n",
      "creating train, valid, test...\n",
      "learn_bpe.py on bpe-iwslt-bpe-iwslt-tokenized.en-vi/tmp/train.en-vi...\n",
      "apply_bpe.py to train.en...\n",
      "apply_bpe.py to valid.en...\n",
      "apply_bpe.py to test.en...\n",
      "apply_bpe.py to train.vi...\n",
      "apply_bpe.py to valid.vi...\n",
      "apply_bpe.py to test.vi...\n",
      "2020-12-02 10:18:41 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='bpe-iwslt-data-bin/tokenized.en-vi', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='en', srcdict=None, target_lang='vi', task='translation', tensorboard_logdir=None, testpref='bpe-iwslt-tokenized.en-vi/test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='bpe-iwslt-tokenized.en-vi/train', user_dir=None, validpref='bpe-iwslt-tokenized.en-vi/valid', wandb_project=None, workers=20)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/fairseq-preprocess\", line 33, in <module>\n",
      "    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-preprocess')())\n",
      "  File \"/home/chinh/clc_fairseq/fairseq_cli/preprocess.py\", line 394, in cli_main\n",
      "    main(args)\n",
      "  File \"/home/chinh/clc_fairseq/fairseq_cli/preprocess.py\", line 74, in main\n",
      "    raise FileExistsError(dict_path(args.source_lang))\n",
      "FileExistsError: bpe-iwslt-data-bin/tokenized.en-vi/dict.en.txt\n"
     ]
    }
   ],
   "source": [
    "# # Download and prepare the data\n",
    "!bash examples/translation/prepare-en-vi-iwslt-only-BPE.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RXKBIen3-URS"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0r2hhjvH-Q5o",
    "outputId": "3c345137-ae3d-41cd-e91b-17d0fe3b85a1",
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "8, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer', attention_dropout=0.0, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='bpe-iwslt-data-bin/tokenized.en-vi', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}', eval_bleu_detok='moses', eval_bleu_detok_args=None, eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, local_rank=0, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=1, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=0, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='bpe-iwslt-checkpoints/fconv_wmt_en_vi', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=400, weight_decay=0.0001, zero_sharding='none'), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 400, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None}\n",
      "2020-12-02 13:20:56 | INFO | fairseq.tasks.translation | [en] dictionary: 7768 types\n",
      "2020-12-02 13:20:56 | INFO | fairseq.tasks.translation | [vi] dictionary: 6768 types\n",
      "2020-12-02 13:20:56 | INFO | fairseq.data.data_utils | loaded 5089 examples from: bpe-iwslt-data-bin/tokenized.en-vi/valid.en-vi.en\n",
      "2020-12-02 13:20:56 | INFO | fairseq.data.data_utils | loaded 5089 examples from: bpe-iwslt-data-bin/tokenized.en-vi/valid.en-vi.vi\n",
      "2020-12-02 13:20:56 | INFO | fairseq.tasks.translation | bpe-iwslt-data-bin/tokenized.en-vi valid en-vi 5089 examples\n",
      "2020-12-02 13:20:58 | INFO | fairseq_cli.train | TransformerModel(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (dropout_module): FairseqDropout()\n",
      "    (embed_tokens): Embedding(7768, 512, padding_idx=1)\n",
      "    (embed_positions): SinusoidalPositionalEmbedding()\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (3): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (4): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (5): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (dropout_module): FairseqDropout()\n",
      "    (embed_tokens): Embedding(6768, 512, padding_idx=1)\n",
      "    (embed_positions): SinusoidalPositionalEmbedding()\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (3): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (4): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (5): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (output_projection): Linear(in_features=512, out_features=6768, bias=False)\n",
      "  )\n",
      ")\n",
      "2020-12-02 13:20:58 | INFO | fairseq_cli.train | task: TranslationTask\n",
      "2020-12-02 13:20:58 | INFO | fairseq_cli.train | model: TransformerModel\n",
      "2020-12-02 13:20:58 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion)\n",
      "2020-12-02 13:20:58 | INFO | fairseq_cli.train | num. model params: 51580928 (num. trained: 51580928)\n",
      "2020-12-02 13:20:58 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
      "2020-12-02 13:20:58 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
      "2020-12-02 13:20:58 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and batch size per GPU = None\n",
      "2020-12-02 13:20:59 | INFO | fairseq.trainer | loaded checkpoint bpe-iwslt-checkpoints/fconv_wmt_en_vi/checkpoint_last.pt (epoch 2 @ 802 updates)\n",
      "2020-12-02 13:20:59 | INFO | fairseq.trainer | loading train data for epoch 2\n",
      "2020-12-02 13:20:59 | INFO | fairseq.data.data_utils | loaded 111966 examples from: bpe-iwslt-data-bin/tokenized.en-vi/train.en-vi.en\n",
      "2020-12-02 13:20:59 | INFO | fairseq.data.data_utils | loaded 111966 examples from: bpe-iwslt-data-bin/tokenized.en-vi/train.en-vi.vi\n",
      "2020-12-02 13:20:59 | INFO | fairseq.tasks.translation | bpe-iwslt-data-bin/tokenized.en-vi train en-vi 111966 examples\n",
      "2020-12-02 13:21:00 | INFO | fairseq_cli.train | done training in 0.0 seconds\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p \"bpe-iwslt-checkpoints/fconv_wmt_en_vi\"\n",
    "\n",
    "!CUDA_VISIBLE_DEVICES=0 fairseq-train \"bpe-iwslt-data-bin/tokenized.en-vi\" \\\n",
    "    --arch transformer --share-decoder-input-output-embed \\\n",
    "    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\\n",
    "    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 400 \\\n",
    "    --dropout 0.3 --weight-decay 0.0001 \\\n",
    "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
    "    --max-tokens 4096 \\\n",
    "    --eval-bleu \\\n",
    "    --eval-bleu-args '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}' \\\n",
    "    --eval-bleu-detok moses \\\n",
    "    --eval-bleu-remove-bpe \\\n",
    "    --eval-bleu-print-samples \\\n",
    "    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \\\n",
    "    --save-dir \"bpe-iwslt-checkpoints/fconv_wmt_en_vi\" \\\n",
    "    --max-epoch 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 920,
     "status": "ok",
     "timestamp": 1606188005510,
     "user": {
      "displayName": "Chinh hoang trung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64",
      "userId": "05604119531382760831"
     },
     "user_tz": -420
    },
    "id": "xvo9_A3MK6p5",
    "outputId": "1476590f-7183-4b47-f289-2095a2a127b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chinh/clc_fairseq\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 802,
     "status": "ok",
     "timestamp": 1606292073968,
     "user": {
      "displayName": "Chinh hoang trung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioUTYb9Muh5-9urDiUXdmGavW-fw5E7QZ4KyH6=s64",
      "userId": "05604119531382760831"
     },
     "user_tz": -420
    },
    "id": "6HHzwi1G_UMr",
    "outputId": "155022f5-16cf-4d08-a7e9-72ad85c535b8",
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "việc với những người đàn ông ta , và tôi đã làm việc với những người đàn ông ta .\n",
      "P-149\t-2.2725 -1.0182 -2.7739 -0.6407 -3.7880 -2.2473 -3.0627 -0.8222 -1.3618 -2.6074 -1.9664 -4.4139 -0.2124 -2.3271 -3.2057 -2.2480 -2.4978 -2.8015 -2.9333 -1.4247 -2.1668 -2.4235 -1.6645 -4.5058 -0.1738 -2.5959 -4.0623 -0.3142\n",
      "S-17\tand the answer , i believe , is yes . &#91; &quot; f = t <unk> s<unk> &quot; &#93; what you &apos;re seeing is probably the closest equivalent to an e = mc <unk> for intelligence that i &apos;ve seen .\n",
      "T-17\ttôi tin , câu trả lời là có . &#91; &quot; f = t <<unk>> s<<unk>> &quot; &#93; cái ta thấy đây có thể là cái tương đương gần nhất với một e = mc ² một công thức cho trí thông minh mà tôi đã thấy .\n",
      "H-17\t-2.2851414680480957\t&lt; speaker &gt;\n",
      "D-17\t-2.2851414680480957\t&lt; speaker &gt;\n",
      "P-17\t-5.0194 -0.0419 -1.2187 -2.8606\n",
      "S-672\thowever , in every religion , in every population , you &apos;ll find a small percentage of people who hold so fervently to their beliefs that they feel they must use any means necessary to make others live as they do .\n",
      "T-672\ttuy nhiên , ở mô <<unk>> i mô ̣ t tôn giáo , mỗi mô ̣ t dân tộc , bạn sẽ thấy có một cơ số nhỏ những người có đức tin mãnh liệt đến nỗi họ thấy rằng cần phải dùng mọi cách để khiến người khác cũng sống như họ .\n",
      "H-672\t-1.9596425294876099\thọ có thể làm việc với họ .\n",
      "D-672\t-1.9596425294876099\thọ có thể làm việc với họ .\n",
      "P-672\t-1.6903 -2.2582 -0.4372 -4.0297 -1.2980 -1.2169 -2.9558 -2.8514 -0.8992\n",
      "S-19\tit acts to maximize future freedom of action , or keep options open , with some strength t , with the diversity of possible accessible futures , s , up to some future time horizon , tau .\n",
      "T-19\tnó hành động để tối đa hóa tự do hành động tương lai , hoặc giữ cho các lựa chọn được để ngỏ , với một cường độ t , với sự đa dạng của các tương lai có thể đạt tới , s trong một ngưỡng thời gian tương lai nào đó , tau .\n",
      "H-19\t-2.676029682159424\tnhưng nếu bạn có thể nhìn vào một phần lớn hơn , nó có thể là một phần lớn hơn , có thể là một phần lớn hơn .\n",
      "D-19\t-2.676029682159424\tnhưng nếu bạn có thể nhìn vào một phần lớn hơn , nó có thể là một phần lớn hơn , có thể là một phần lớn hơn .\n",
      "P-19\t-3.7988 -2.0195 -2.1908 -2.4964 -1.1912 -3.5798 -1.0292 -2.7527 -4.8986 -2.5329 -2.1328 -1.3729 -4.8056 -2.6947 -1.7651 -3.2788 -1.7757 -4.7188 -2.6295 -1.8671 -2.3781 -4.3396 -1.9791 -3.5173 -2.0295 -4.7276 -2.5453 -1.8497 -3.1876 -0.1962\n",
      "S-656\tand that quote , &quot; the only disability in life is a bad attitude , &quot; the reason that that &apos;s bullshit is because it &apos;s just not true , because of the social model of disability .\n",
      "T-656\tvà câu nói : &quot; khiếm khuyết duy nhất trong cuộc sống là một thái độ tồi , &quot; lí do thật là vớ vẩn bởi vì nó không đúng , bởi vì hình mẫu xã hội về sự tàn tật là sai .\n",
      "H-656\t-2.352245807647705\tnó không phải là một người đàn ông ta , và nó không phải là một người đàn ông ta không phải là một người đàn ông . &quot;\n",
      "D-656\t-2.352245807647705\tnó không phải là một người đàn ông ta , và nó không phải là một người đàn ông ta không phải là một người đàn ông . &quot;\n",
      "P-656\t-4.2054 -1.5302 -1.2974 -0.2592 -1.5760 -4.2091 -3.0185 -0.1580 -2.6374 -2.6807 -2.2623 -4.2709 -1.8303 -3.1094 -0.8600 -2.2483 -3.7581 -3.3120 -0.1517 -2.4928 -2.4345 -3.5283 -2.4889 -2.5341 -3.6872 -3.5978 -0.1363 -3.6508 -2.3428 -0.2990\n",
      "S-60\tyour closet may be telling someone you love her for the first time , or telling someone that you &apos;re pregnant , or telling someone you have cancer , or any of the other hard conversations we have throughout our lives .\n",
      "T-60\tkhó khăn của bạn có thể là nói cho một ai đó biết rằng bạn yêu cô ấy ngay từ lần gặp mặt đầu tiên , hay bạn đang mang bầu , hay bạn mắc bệnh ung thư , hay bất kì những cuộc trò chuyện khó nói mà chúng ta đã từng có trong suốt đời mình .\n",
      "H-60\t-2.2690675258636475\tnhưng nếu bạn nói , &quot; chúng ta có thể làm việc với những người khác , &quot; chúng ta có thể nói , &quot; chúng ta có thể làm việc với những người khác . &quot;\n",
      "D-60\t-2.2690675258636475\tnhưng nếu bạn nói , &quot; chúng ta có thể làm việc với những người khác , &quot; chúng ta có thể nói , &quot; chúng ta có thể làm việc với những người khác . &quot;\n",
      "P-60\t-4.0256 -2.3361 -1.3457 -2.9304 -2.0450 -1.1962 -3.2949 -0.4297 -3.6238 -0.7728 -3.7327 -1.4916 -1.8807 -2.9633 -1.9818 -3.7332 -2.1745 -1.1667 -4.0099 -0.5114 -3.5718 -0.9570 -3.2831 -2.6785 -0.8614 -4.4107 -0.5830 -3.4649 -1.0646 -3.4869 -2.0419 -2.3718 -2.7526 -1.9214 -3.4332 -2.6324 -0.7167 -0.3469\n",
      "S-1062\tarchitects are no longer these mysterious creatures that use big words and complicated drawings , and you aren &apos;t the hapless public , the consumer that won &apos;t accept anything that they haven &apos;t seen anymore .\n",
      "T-1062\tkiến trúc sư không còn là những sinh vật bí ẩn với những ngôn từ to tát và những bản vẽ phức tạp , và các bạn không còn là công chúng thiếu may mắn , là người sử dụng vốn không chấp nhận bất cứ thứ gì mà họ chưa từng thấy nữa .\n",
      "H-1062\t-2.414527654647827\tvà không phải là những người khác nhau , và họ không có những người khác nhau .\n",
      "D-1062\t-2.414527654647827\tvà không phải là những người khác nhau , và họ không có những người khác nhau .\n",
      "P-1062\t-1.9790 -3.8052 -1.2773 -1.0732 -3.3241 -1.8997 -3.4326 -2.8569 -2.4682 -2.7241 -3.1340 -1.3502 -2.8121 -3.3947 -1.6160 -3.2086 -2.4085 -2.7259 -0.3858\n",
      "S-50\tgoing back to the beginning of the usage of the term robot , the play &quot; rur , &quot; there was always a concept that if we developed machine intelligence , there would be a cybernetic revolt .\n",
      "T-50\tđưa ta trở về điểm ban đầu lúc bắt đầu sử dụng khái niệm robot , vở kịch &quot; rur , &quot; luôn có một khái niệm rằng nếu ta phát triển một trí thông minh nhân tạo , thì có thể xảy ra cuộc nổi loạn về điều khiển học .\n",
      "H-50\t-1.7737112045288086\t&lt; speaker &gt;\n",
      "D-50\t-1.7737112045288086\t&lt; speaker &gt;\n",
      "P-50\t-3.7754 -0.0246 -0.7521 -2.5427\n",
      "S-772\tfaced with an anomaly like this , radical ideas may be needed , and i think that we may need one or two ideas that initially seem crazy before we can come to grips with consciousness scientifically .\n",
      "T-772\tđối mặt với một thứ dị thường như thế này , sẽ cần những ý tường cấp tiến và thôi nghĩ rằng chúng ta sẽ cần một hoặc hai ý tướng ban đầu , nghe có vẻ điên khùng trước khi chúng ta hiểu biết một cách khoa học .\n",
      "H-772\t-2.176870822906494\tvà tôi nghĩ rằng chúng ta có thể làm việc với những gì chúng ta có thể tạo ra một cách nào đó .\n",
      "D-772\t-2.176870822906494\tvà tôi nghĩ rằng chúng ta có thể làm việc với những gì chúng ta có thể tạo ra một cách nào đó .\n",
      "P-772\t-2.3804 -2.5707 -1.9613 -0.7177 -3.6834 -0.4531 -2.2382 -1.0379 -3.6125 -1.1629 -1.7422 -3.0635 -3.6006 -2.5362 -0.4559 -2.5668 -0.9327 -4.9040 -0.4104 -2.1266 -3.2074 -3.9182 -1.5772 -3.2423 -0.3198\n",
      "S-942\twhat would it mean for her if she were freed from that voice of her inner critic , nagging her to have longer legs , thinner thighs , smaller stomach , shorter feet ?\n",
      "T-942\tđiều có ý nghĩa gì với cô ấy nếu cô ấy được giải phóng khỏi tiếng nói nội tâm đang phê phán , quở trách bản thân để có chân dài hơn , đùi thon hơn dạ dày nhỏ hơn , bàn chân ngắn hơn ?\n",
      "H-942\t-2.102199077606201\tvà ông ấy nói , &quot; cô ấy không ? &quot;\n",
      "D-942\t-2.102199077606201\tvà ông ấy nói , &quot; cô ấy không ? &quot;\n",
      "P-942\t-3.2677 -3.9257 -1.4888 -2.2662 -1.2884 -0.6180 -4.5381 -1.1746 -2.1809 -2.7531 -0.6050 -1.1196\n",
      " 86%|██████████████████████████████▊     | 6/7 [02:17<00:26, 26.51s/it, wps=107]S-1071\tand it means that a building doesn &apos;t have to be beautiful to be lovable , like this ugly little building in spain , where the architects dug a hole , packed it with hay , and then poured concrete around it , and when the concrete dried , they invited someone to come and clean that hay out so that all that &apos;s left when it &apos;s done is this hideous little room that &apos;s filled with the imprints and scratches of how that place was made , and that becomes the most sublime place to watch a spanish sunset .\n",
      "T-1071\tvà nó có nghĩa là một toà nhà không cần phải đẹp , phải được yêu thích , như ngôi nhà nhỏ bé xấu xí này ở tây ban nha , nơi mà các kiến trúc sư đã đào một cái lỗ , lớp nó với rơm , và sau đó đổ vữa xung quanh nó , và khi vữa khô lại , họ mời một ai đó đến và làm sạch tất cả rơm rạ , để khi tất cả những thứ đó kết thúc , để lại là căn phòng nhỏ bé gồ ghề này , chứa đầy những dấu tích và vết cào xước của quá trình tạo ra nơi này , và nó trở thành một nơi tuyệt vời để ngắm nhìn hoàng hôn tây ban nha .\n",
      "H-1071\t-2.6022768020629883\tvà điều này không phải là một người đàn ông ấy , và có một người đàn ông ta không có một người đàn ông , và không có những người khác .\n",
      "D-1071\t-2.6022768020629883\tvà điều này không phải là một người đàn ông ấy , và có một người đàn ông ta không có một người đàn ông , và không có những người khác .\n",
      "P-1071\t-1.3092 -4.3993 -1.7918 -2.8759 -2.1147 -0.4522 -2.5364 -3.9451 -2.5972 -0.1399 -3.1229 -2.8691 -1.5385 -4.7199 -2.7682 -3.5643 -3.0642 -0.1174 -2.9206 -2.7282 -3.0347 -3.1781 -3.6331 -3.3408 -0.1080 -4.0868 -1.5710 -4.1829 -3.0138 -3.6482 -1.7352 -3.7131 -3.3218 -0.3349\n",
      "S-114\ti could go back to my girlfriend and my gay-loving table and mock their responses , chastise their unworldliness and their inability to jump through the politically correct gay hoops i had brought with me , or i could empathize with them and realize that that was maybe one of the hardest things they had ever done , that starting and having that conversation was them coming out of their closets .\n",
      "T-114\ttôi có thể quay trở lại chỗ bạn gái mình quay lại bàn những người bạn đồng tính của mình và bắt chước phản ứng của họ , vẻ bộ thanh cao và sự bất lực của họ khi cố gắng tránh từ ngữ thiếu tôn trọng người đồng tính khi nói chuyện với tôi hoặc tôi có thể thông cảm với họ và nhận ra rằng đây có lẽ là một trong những vấn đề khó khăn nhất , mà họ từng gặp , rằng việc họ bắt đầu những cuộc trò chuyện chính là lúc họ bước ra khỏi chiếc tủ của mình .\n",
      "H-114\t-2.393216133117676\tvà tôi nghĩ rằng họ đã làm việc với những người đàn ông ấy , và họ đã làm việc với những người đàn ông ấy , và họ có thể làm việc với những người đàn ông .\n",
      "D-114\t-2.393216133117676\tvà tôi nghĩ rằng họ đã làm việc với những người đàn ông ấy , và họ đã làm việc với những người đàn ông ấy , và họ có thể làm việc với những người đàn ông .\n",
      "P-114\t-1.9455 -1.6729 -3.4218 -0.8323 -1.6982 -2.6409 -3.2035 -0.9140 -1.3133 -2.8366 -1.3063 -4.4009 -0.1984 -3.1248 -3.2354 -2.1079 -2.2056 -3.3103 -3.0961 -1.5644 -2.2845 -2.8614 -1.1052 -4.5399 -0.1796 -3.2301 -3.4681 -2.2324 -2.1971 -4.3741 -2.0038 -3.2725 -1.6454 -2.8565 -2.8629 -1.1191 -4.6453 -0.2066 -5.0975 -0.5175\n",
      "S-1049\twe proposed a building that was audacious , that was different than any of the forms that the community was used to , and we were scared and our client was scared and the community was scared , so we created a series of photorealistic renderings that we put onto facebook and we put onto instagram , and we let people start to do what they do : share it , comment , like it , hate it .\n",
      "T-1049\tchúng ta đã đề xuất một toà nhà rất táo bạo , rất khác biệt với tất cả những khuôn mẫu mà cộng đồng vốn quen thuộc , và chúng tôi lo lắng và khách hàng của chúng tôi cũng cảm thấy lo lắng và cộng đồng cũng lo lắng , nên chúng tôi đã tạo ra một loạt những bản dựng hình ảnh như thật và chúng tôi đăng lên facebook và chúng tôi đăng lên instagram , và chúng tôi để mọi người bắt đầu làm điều mà họ làm : chia sẻ nó , bình luận , thích nó , ghét nó .\n",
      "H-1049\t-2.2460386753082275\tvà chúng ta có thể làm việc với những người khác nhau , và chúng ta có thể làm việc với những người khác nhau .\n",
      "D-1049\t-2.2460386753082275\tvà chúng ta có thể làm việc với những người khác nhau , và chúng ta có thể làm việc với những người khác nhau .\n",
      "P-1049\t-1.7809 -2.2883 -0.8865 -2.8538 -1.1221 -3.9826 -1.4175 -1.6293 -3.1481 -2.2798 -3.4460 -2.7269 -1.9421 -1.6773 -3.1659 -0.6638 -2.8389 -1.3195 -3.6239 -1.8036 -2.4209 -2.9622 -1.9778 -3.2825 -1.8009 -3.1831 -0.4188\n",
      "S-239\tladies and gentlemen , this plight of millions of women could be changed if we think differently , if women and men think differently , if men and women in the tribal and patriarchal societies in the developing countries , if they can break a few norms of family and society , if they can abolish the discriminatory laws of the systems in their states , which go against the basic human rights of the women .\n",
      "T-239\tkính thưa quý bà và quý ông cảnh ngộ nghiệt ngã mà hàng triệu phụ nữ gặp phải này có thể được thay đổi nếu chúng ta suy nghĩ khác đi , nếu phụ nữ và nam giới suy nghĩ khác đi , nếu đàn ông và phụ nữ trong xã hội phụ hệ và mang tính bộ lạc ở các nước đang phát triển , nếu họ có thể phá vỡ luật lệ về gia đình và xã hội , nếu họ có thể bãi bỏ luật phân biệt đối xử trong hệ thống xã hội của mình , những thứ mà đi ngược lại các nhân quyền cơ bản của phụ nữ .\n",
      "H-239\t-2.3481037616729736\tchúng ta có thể làm việc với những người khác nhau , và họ có thể làm việc với những người khác nhau , và họ có thể làm việc với những người khác nhau , và họ có thể làm việc với những người khác nhau , và họ có thể làm việc với những người khác nhau .\n",
      "D-239\t-2.3481037616729736\tchúng ta có thể làm việc với những người khác nhau , và họ có thể làm việc với những người khác nhau , và họ có thể làm việc với những người khác nhau , và họ có thể làm việc với những người khác nhau , và họ có thể làm việc với những người khác nhau .\n",
      "P-239\t-2.7628 -1.0736 -1.8675 -0.6605 -4.1529 -1.4161 -1.4625 -2.8855 -2.0042 -3.5438 -2.4112 -1.9670 -1.7976 -3.1279 -2.4135 -1.0672 -3.6077 -1.6211 -2.3462 -2.8127 -1.6538 -3.3805 -1.6208 -2.1802 -2.5863 -2.8252 -2.6840 -1.2255 -3.5370 -1.6852 -2.6509 -2.9461 -1.5966 -3.2904 -1.4900 -2.2335 -2.7324 -2.7947 -2.8740 -1.2355 -3.5168 -1.7283 -2.6777 -2.9502 -1.5560 -3.2459 -1.4858 -2.2409 -2.7311 -2.7808 -3.1683 -1.2586 -3.5723 -1.7718 -2.7862 -3.0120 -1.5101 -3.1679 -1.7236 -3.8230 -0.3028\n",
      "S-9\tyou observe that , over the course of the millennia , earth is continually bombarded with asteroids up until a point , and that at some point , corresponding roughly to our year , 2000 ad , asteroids that are on a collision course with the earth that otherwise would have collided mysteriously get deflected or they detonate before they can hit the earth .\n",
      "T-9\tquý vị sẽ thấy rằng , qua hàng thiên nhiên kỉ , trái đất đã liên tục va chạm với những thiên thạch cho đến một thời điểm tại đó , ứng những năm của chúng ta , khoảng 2000 năm sau cn thời điểm những thiên thạch đang bay theo hướng sắp va vào trái đất hẳn sẽ va vào trái đất thì chợt bị làm chệch hướng hoặc nổ tung trước khi va .\n",
      "H-9\t-2.514833450317383\tvà nếu chúng ta có thể làm việc với những người dân chủ đề này , chúng ta có thể làm việc với những người khác nhau .\n",
      "D-9\t-2.514833450317383\tvà nếu chúng ta có thể làm việc với những người dân chủ đề này , chúng ta có thể làm việc với những người khác nhau .\n",
      "P-9\t-2.5206 -3.0918 -2.0953 -1.0442 -3.1092 -1.3026 -4.3535 -1.2083 -1.7929 -3.1931 -2.7123 -4.9455 -1.5469 -2.5698 -3.3027 -1.2783 -4.6988 -1.1067 -2.3502 -1.3355 -4.1333 -1.5431 -2.2862 -3.1381 -2.4617 -3.9033 -1.7112 -3.8861 -0.3088\n",
      "S-36\tjust as some animals can use objects in their environments as tools to reach into narrow spaces , here we see that entropica , again on its own initiative , was able to move a large disk representing an animal around so as to cause a small disk , representing a tool , to reach into a confined space holding a third disk and release the third disk from its initially fixed position .\n",
      "T-36\thệt như một số động vật có thể dùng các vật thể trong môi trường làm công cụ để vươn ra trong một không gian hẹp đây ta thấy máy entropica , vẫn dựa vào tài trí của mình , có khả năng di chuyển một đĩa lớn tượng trưng cho một con vật dịch chuyển đó khiến cho một đĩa nhỏ , tượng trưng cho một công cụ , vươn ra trong không gian giới hạn nắm lấy cái đĩa thứ ba và thả chiếc đĩa thứ ba từ vị trí cố định ban đầu của nó .\n",
      "H-36\t-2.3343887329101562\tchúng ta có thể tạo ra một cách khác nhau , và chúng ta có thể tạo ra một cách khác nhau .\n",
      "D-36\t-2.3343887329101562\tchúng ta có thể tạo ra một cách khác nhau , và chúng ta có thể tạo ra một cách khác nhau .\n",
      "P-36\t-3.2634 -1.0888 -1.7066 -1.0462 -4.7607 -0.3934 -1.0932 -4.1871 -3.5859 -2.4001 -2.4823 -1.5624 -4.8141 -0.9279 -1.8203 -1.3153 -4.4222 -0.4332 -1.3024 -3.9165 -3.7738 -1.7444 -3.6007 -0.3845\n",
      "S-140\tand we know it &apos;s hard but we need you out here , no matter what your walls are made of , because i guarantee you there are others peering through the keyholes of their closets looking for the next brave soul to bust a door open , so be that person and show the world that we are bigger than our closets and that a closet is no place for a person to truly live .\n",
      "T-140\tvà chúng tôi biết việc này là khó nhưng chúng tôi cần bạn bước ra khỏi đó , cho dù chiếc tủ của bạn được làm từ thứ gì , bởi vì tôi cam đoan với bạn rằng có những người khác đang nhòm qua lỗ khóa chiếc tủ của họ để tìm kiếm linh hồn dũng cảm tiếp theo lao ra khỏi cánh cửa tủ , để trở thành con người đó và để cho thế giới này thấy rằng chúng ta to lớn hơn cả những chiếc tủ của mình rằng một chiếc tủ không phải là nơi mà một con người thực sự sống .\n",
      "H-140\t-2.4503681659698486\tvà khi tôi nghĩ rằng chúng ta có thể làm việc với những gì chúng ta có thể làm việc với những người khác nhau , và không phải là những gì chúng ta có những người khác nhau .\n",
      "D-140\t-2.4503681659698486\tvà khi tôi nghĩ rằng chúng ta có thể làm việc với những gì chúng ta có thể làm việc với những người khác nhau , và không phải là những gì chúng ta có những người khác nhau .\n",
      "P-140\t-1.6875 -3.6909 -2.1555 -2.7657 -0.9217 -3.7526 -0.3995 -3.5904 -1.1153 -3.7389 -1.1022 -2.0291 -2.7441 -3.3436 -3.1313 -0.4368 -3.5199 -1.0146 -3.5133 -2.2627 -2.6472 -2.7134 -2.6137 -2.7658 -2.5064 -2.3816 -2.0122 -4.3735 -2.9695 -0.9013 -3.6074 -2.8785 -2.9184 -0.4095 -3.5241 -3.4725 -2.3314 -2.9710 -2.4719 -2.7363 -0.3440\n",
      "S-362\ti &apos;m wondering what you would say , especially to parents , but in a more broad way , to friends , to family , to anyone who finds themselves encountering a child or a person who is struggling with and uncomfortable with a gender that &apos;s being assigned them , what might you say to the family members of that person to help them become good and caring and kind family members to them ?\n",
      "T-362\tbạn sẽ nói gì với các bậc cha mẹ , xa hơn nữa , là bạn bè , gia đình , hay bất cứ ai đang tìm cách đối diện với một đứa trẻ hay người nào đó gặp khó khăn về giới tính của mình. bạn sẽ nói gì với những người trong gia đình của họ để giúp những người này cảm thấy thoải mái , quan tâm và đối xử tử tế với những người đó ?\n",
      "H-362\t-2.5033609867095947\tvà khi tôi nói rằng , &quot; bạn có thể làm việc với những người đàn ông ta có thể nói , &quot; họ có thể làm việc với những người đàn ông ta có thể nói chuyện với họ , &quot; họ , &quot; họ có thể làm việc với những người khác . &quot;\n",
      "D-362\t-2.5033609867095947\tvà khi tôi nói rằng , &quot; bạn có thể làm việc với những người đàn ông ta có thể nói , &quot; họ có thể làm việc với những người đàn ông ta có thể nói chuyện với họ , &quot; họ , &quot; họ có thể làm việc với những người khác . &quot;\n",
      "P-362\t-2.0142 -3.1107 -2.2804 -2.7267 -2.3445 -2.8504 -1.4480 -3.0762 -3.1034 -1.1245 -3.9799 -1.1786 -2.1882 -3.1875 -1.3181 -4.5269 -0.1284 -3.0037 -3.6672 -1.2424 -3.7587 -3.1807 -1.3482 -2.6785 -3.6051 -1.4501 -3.6344 -1.6585 -2.5120 -3.2842 -1.2632 -4.6421 -0.1139 -3.2117 -3.6992 -1.3243 -4.1293 -3.0753 -1.5175 -2.1650 -3.0878 -1.4299 -3.2582 -3.4852 -1.5023 -3.0211 -3.7739 -1.3155 -3.6680 -1.7069 -2.6351 -3.3457 -1.2455 -3.6457 -3.5838 -0.7032 -0.5320\n",
      "2020-12-02 13:28:20 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
      "2020-12-02 13:28:20 | INFO | fairseq_cli.generate | Translated 1080 sentences (14939 tokens) in 128.9s (8.38 sentences/s, 115.92 tokens/s)\n",
      "Generate test with beam=5: BLEU4 = 1.10, 30.7/5.9/1.2/0.2 (BP=0.409, ratio=0.528, syslen=13859, reflen=26244)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "# !mkdir -p iwslt-data-bin-v2/fconv_wmt_en_vi\n",
    "!fairseq-generate \\\n",
    "    bpe-iwslt-data-bin/tokenized.en-vi/ \\\n",
    "    --path bpe-iwslt-checkpoints/fconv_wmt_en_vi/checkpoint_best.pt \\\n",
    "    --beam 5 --remove-bpe | tee bpe-iwslt-checkpoints/fconv_wmt_en_vi/gen.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2IecrmTbBni"
   },
   "source": [
    "Compute BLEU score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "KAHR1vuYbC4R"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Namespace(ignore_case=False, order=4, ref='gen.out.ref', sacrebleu=False, sentence_bleu=False, sys='gen.out.sys')\n",
      "BLEU4 = 1.10, 30.7/5.9/1.2/0.2 (BP=0.409, ratio=0.528, syslen=13859, reflen=26244)\n"
     ]
    }
   ],
   "source": [
    "!grep ^H bpe-iwslt-checkpoints/fconv_wmt_en_vi/gen.out | cut -f3- > gen.out.sys\n",
    "!grep ^T bpe-iwslt-checkpoints/fconv_wmt_en_vi/gen.out | cut -f2- > gen.out.ref\n",
    "!fairseq-score --sys gen.out.sys --ref gen.out.ref\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BLEU4 = 1.1, thấp kỷ lục"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Fairseq - 0622 en-vi TED data v1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}